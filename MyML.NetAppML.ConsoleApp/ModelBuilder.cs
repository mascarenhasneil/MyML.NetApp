// This file was auto-generated by ML.NET Model Builder. 

using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using Microsoft.ML;
using Microsoft.ML.Data;
using MyML_NetAppML.Model;

namespace MyML_NetAppML.ConsoleApp
{
    internal static class Resources
    {
        public const string TrainingModel = "=============== Training  model ===============";
        public const string EndOfTraining = "=============== End of training process ===============";
        public const string CrossValidating = "=============== Cross-validating to get model's accuracy metrics ===============";
        public const string SavingModel = "=============== Saving the model  ===============";
        public const string ModelSaved = "The model is saved to {0}";
        public const string MetricsHeader = "************************************************************";
        public const string MetricsTitle = "*    Metrics for multi-class classification model   ";
        public const string MetricsSeparator = "*-----------------------------------------------------------";
        public const string MetricsFooter = "************************************************************";
        public const string FoldsHeader = "*************************************************************************************************************";
        public const string FoldsTitle = "*       Metrics for Multi-class Classification model      ";
        public const string FoldsSeparator = "*------------------------------------------------------------------------------------------------------------";
        public const string FoldsFooter = "*************************************************************************************************************";
        public const string UsingModelToMakeSinglePrediction = "Using model to make single prediction -- Comparing actual Sentiment with predicted Sentiment from sample data...";
        public const string EndOfProcessMessage = "=============== End of process, hit any key to finish ===============";
    }

    public static class ModelBuilder
    {
        private static string s_train_data_file_path = @"C:\Users\MascarenhasNeil\Source\Repos\MyML.NetApp\MyML.NetApp\Data\wikipedia-detox-250-line-data.tsv";
        private static string s_modle_File = ConsumeModel.MLNetModelPath;

        // Create MLContext to be shared across the model creation workflow objects 
        // Set a random seed for repeatable/deterministic results across multiple trainings.
        private static MLContext s_mlContext = new MLContext(seed: 1);

        public static void CreateModel()
        {
            // Load Data
            IDataView trainingDataView = s_mlContext.Data.LoadFromTextFile<ModelInput>(
                                            path: s_train_data_file_path,
                                            hasHeader: true,
                                            separatorChar: '\t',
                                            allowQuoting: true,
                                            allowSparse: false);

            // Build training pipeline
            IEstimator<ITransformer> trainingPipeline = BuildTrainingPipeline(s_mlContext);

            // Train Model
            ITransformer mlModel = TrainModel(s_mlContext, trainingDataView, trainingPipeline);

            // Evaluate quality of Model
            Evaluate(s_mlContext, trainingDataView, trainingPipeline);

            // Save model
            SaveModel(s_mlContext, mlModel, s_modle_File, trainingDataView.Schema);
        }

        public static IEstimator<ITransformer> BuildTrainingPipeline(MLContext mlContext)
        {
            ArgumentNullException.ThrowIfNull(mlContext);
            // Data process configuration with pipeline data transformations 
            var dataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey("Sentiment", "Sentiment")
                                      .Append(mlContext.Transforms.Text.FeaturizeText("SentimentText_tf", "SentimentText"))
                                      .Append(mlContext.Transforms.CopyColumns("Features", "SentimentText_tf"))
                                      .Append(mlContext.Transforms.NormalizeMinMax("Features", "Features"))
                                      .AppendCacheCheckpoint(mlContext);
            // Set the training algorithm 
            var trainer = mlContext.MulticlassClassification.Trainers.OneVersusAll(mlContext.BinaryClassification.Trainers.AveragedPerceptron(labelColumnName: "Sentiment", numberOfIterations: 10, featureColumnName: "Features"), labelColumnName: "Sentiment")
                                      .Append(mlContext.Transforms.Conversion.MapKeyToValue("PredictedLabel", "PredictedLabel"));

            var trainingPipeline = dataProcessPipeline.Append(trainer);

            return trainingPipeline;
        }

        public static ITransformer TrainModel(MLContext mlContext, IDataView trainingDataView, IEstimator<ITransformer> trainingPipeline)
        {
            ArgumentNullException.ThrowIfNull(mlContext);
            ArgumentNullException.ThrowIfNull(trainingDataView);
            ArgumentNullException.ThrowIfNull(trainingPipeline);
            Console.WriteLine(Resources.TrainingModel);

            ITransformer model = trainingPipeline.Fit(trainingDataView);

            Console.WriteLine(Resources.EndOfTraining);
            return model;
        }

        private static void Evaluate(MLContext mlContext, IDataView trainingDataView, IEstimator<ITransformer> trainingPipeline)
        {
            ArgumentNullException.ThrowIfNull(mlContext);
            ArgumentNullException.ThrowIfNull(trainingDataView);
            ArgumentNullException.ThrowIfNull(trainingPipeline);
            // Cross-Validate with single dataset (since we don't have two datasets, one for training and for evaluate)
            // in order to evaluate and get the model's accuracy metrics
            Console.WriteLine(Resources.CrossValidating);
            var crossValidationResults = mlContext.MulticlassClassification.CrossValidate(trainingDataView, trainingPipeline, numberOfFolds: 5, labelColumnName: "Sentiment");
            PrintMulticlassClassificationFoldsAverageMetrics(crossValidationResults);
        }

        private static void SaveModel(MLContext mlContext, ITransformer mlModel, string modelRelativePath, DataViewSchema modelInputSchema)
        {
            ArgumentNullException.ThrowIfNull(mlContext);
            ArgumentNullException.ThrowIfNull(mlModel);
            ArgumentNullException.ThrowIfNull(modelRelativePath);
            ArgumentNullException.ThrowIfNull(modelInputSchema);
            // Save/persist the trained model to a .ZIP file
            Console.WriteLine(Resources.SavingModel);
            mlContext.Model.Save(mlModel, modelInputSchema, GetAbsolutePath(modelRelativePath));
            Console.WriteLine(string.Format(Resources.ModelSaved, GetAbsolutePath(modelRelativePath)));
        }

        public static string GetAbsolutePath(string relativePath)
        {
            FileInfo dataRoot = new FileInfo(typeof(Program).Assembly.Location);
            string assemblyFolderPath = dataRoot.Directory.FullName;

            string fullPath = Path.Combine(assemblyFolderPath, relativePath);

            return fullPath;
        }

        public static void PrintMulticlassClassificationMetrics(MulticlassClassificationMetrics metrics)
        {
            ArgumentNullException.ThrowIfNull(metrics);
            Console.WriteLine(Resources.MetricsHeader);
            Console.WriteLine(Resources.MetricsTitle);
            Console.WriteLine(Resources.MetricsSeparator);
            Console.WriteLine($"    MacroAccuracy = {metrics.MacroAccuracy:0.####}, a value between 0 and 1, the closer to 1, the better");
            Console.WriteLine($"    MicroAccuracy = {metrics.MicroAccuracy:0.####}, a value between 0 and 1, the closer to 1, the better");
            Console.WriteLine($"    LogLoss = {metrics.LogLoss:0.####}, the closer to 0, the better");
            for (int i = 0; i < metrics.PerClassLogLoss.Count; i++)
            {
                Console.WriteLine($"    LogLoss for class {i + 1} = {metrics.PerClassLogLoss[i]:0.####}, the closer to 0, the better");
            }
            Console.WriteLine(Resources.MetricsFooter);
        }

        public static void PrintMulticlassClassificationFoldsAverageMetrics(IEnumerable<TrainCatalogBase.CrossValidationResult<MulticlassClassificationMetrics>> crossValResults)
        {
            ArgumentNullException.ThrowIfNull(crossValResults);
            var resultsList = crossValResults.ToList();

            var metricsInMultipleFolds = resultsList.Select(r => r.Metrics).ToList();

            var microAccuracyValues = metricsInMultipleFolds.Select(m => m.MicroAccuracy).ToList();
            var microAccuracyAverage = microAccuracyValues.Average();
            var microAccuraciesStdDeviation = CalculateStandardDeviation(microAccuracyValues);
            var microAccuraciesConfidenceInterval95 = CalculateConfidenceInterval95(microAccuracyValues);

            var macroAccuracyValues = metricsInMultipleFolds.Select(m => m.MacroAccuracy).ToList();
            var macroAccuracyAverage = macroAccuracyValues.Average();
            var macroAccuraciesStdDeviation = CalculateStandardDeviation(macroAccuracyValues);
            var macroAccuraciesConfidenceInterval95 = CalculateConfidenceInterval95(macroAccuracyValues);

            var logLossValues = metricsInMultipleFolds.Select(m => m.LogLoss).ToList();
            var logLossAverage = logLossValues.Average();
            var logLossStdDeviation = CalculateStandardDeviation(logLossValues);
            var logLossConfidenceInterval95 = CalculateConfidenceInterval95(logLossValues);

            var logLossReductionValues = metricsInMultipleFolds.Select(m => m.LogLossReduction).ToList();
            var logLossReductionAverage = logLossReductionValues.Average();
            var logLossReductionStdDeviation = CalculateStandardDeviation(logLossReductionValues);
            var logLossReductionConfidenceInterval95 = CalculateConfidenceInterval95(logLossReductionValues);

            Console.WriteLine(Resources.FoldsHeader);
            Console.WriteLine(Resources.FoldsTitle);
            Console.WriteLine(Resources.FoldsSeparator);
            Console.WriteLine($"*       Average MicroAccuracy:    {microAccuracyAverage:0.###}  - Standard deviation: ({microAccuraciesStdDeviation:#.###})  - Confidence Interval 95%: ({microAccuraciesConfidenceInterval95:#.###})");
            Console.WriteLine($"*       Average MacroAccuracy:    {macroAccuracyAverage:0.###}  - Standard deviation: ({macroAccuraciesStdDeviation:#.###})  - Confidence Interval 95%: ({macroAccuraciesConfidenceInterval95:#.###})");
            Console.WriteLine($"*       Average LogLoss:          {logLossAverage:#.###}  - Standard deviation: ({logLossStdDeviation:#.###})  - Confidence Interval 95%: ({logLossConfidenceInterval95:#.###})");
            Console.WriteLine($"*       Average LogLossReduction: {logLossReductionAverage:#.###}  - Standard deviation: ({logLossReductionStdDeviation:#.###})  - Confidence Interval 95%: ({logLossReductionConfidenceInterval95:#.###})");
            Console.WriteLine(Resources.FoldsFooter);

        }

        public static double CalculateStandardDeviation(IEnumerable<double> values)
        {
            ArgumentNullException.ThrowIfNull(values);
            var valuesList = values.ToList();
            double average = valuesList.Average();
            double sumOfSquaresOfDifferences = valuesList.Select(val => (val - average) * (val - average)).Sum();
            double standardDeviation = Math.Sqrt(sumOfSquaresOfDifferences / (valuesList.Count - 1));
            return standardDeviation;
        }

        public static double CalculateConfidenceInterval95(IEnumerable<double> values)
        {
            ArgumentNullException.ThrowIfNull(values);
            var valuesList = values.ToList();
            double confidenceInterval95 = 1.96 * CalculateStandardDeviation(valuesList) / Math.Sqrt((valuesList.Count - 1));
            return confidenceInterval95;
        }
    }
}
